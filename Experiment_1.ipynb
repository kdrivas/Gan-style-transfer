{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-45656b549404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'generator'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import generator\n",
    "import discriminator\n",
    "import helpers\n",
    "\n",
    "\n",
    "CUDA = True\n",
    "VOCAB_SIZE = 5000\n",
    "MAX_SEQ_LEN = 20\n",
    "START_LETTER = 0\n",
    "BATCH_SIZE = 32\n",
    "MLE_TRAIN_EPOCHS = 100\n",
    "ADV_TRAIN_EPOCHS = 50\n",
    "POS_NEG_SAMPLES = 10000\n",
    "\n",
    "GEN_EMBEDDING_DIM = 32\n",
    "GEN_HIDDEN_DIM = 32\n",
    "DIS_EMBEDDING_DIM = 64\n",
    "DIS_HIDDEN_DIM = 64\n",
    "\n",
    "oracle_samples_path = './oracle_samples.trc'\n",
    "oracle_state_dict_path = './oracle_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_gen_path = './gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_dis_path = './dis_pretrain_EMBDIM_64_HIDDENDIM64_VOCAB5000_MAXSEQLEN20.trc'\n",
    "\n",
    "\n",
    "def train_generator_MLE(gen, gen_opt, oracle, real_data_samples, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pretraining for the generator\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch %d : ' % (epoch + 1), end='')\n",
    "        sys.stdout.flush()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "            inp, target = helpers.prepare_generator_batch(real_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "                                                          gpu=CUDA)\n",
    "            gen_opt.zero_grad()\n",
    "            loss = gen.batchNLLLoss(inp, target)\n",
    "            loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            total_loss += loss.data.item()\n",
    "\n",
    "            if (i / BATCH_SIZE) % ceil(\n",
    "                            ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        # each loss in a batch is loss per sample\n",
    "        total_loss = total_loss / ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
    "\n",
    "        # sample from generator and compute oracle NLL\n",
    "        oracle_loss = helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                                                   start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "        print(' average_train_NLL = %.4f, oracle_sample_NLL = %.4f' % (total_loss, oracle_loss))\n",
    "\n",
    "\n",
    "def train_generator_PG(gen, gen_opt, oracle, dis, num_batches):\n",
    "    \"\"\"\n",
    "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        s = gen.sample(BATCH_SIZE*2)        # 64 works best\n",
    "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
    "        rewards = dis.batchClassify(target)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
    "        pg_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "    # sample from generator and compute oracle NLL\n",
    "    oracle_loss = helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                                                   start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "    print(' oracle_sample_NLL = %.4f' % oracle_loss)\n",
    "\n",
    "\n",
    "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, oracle, d_steps, epochs):\n",
    "    \"\"\"\n",
    "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
    "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # generating a small validation set before training (using oracle and generator)\n",
    "    pos_val = oracle.sample(100)\n",
    "    neg_val = generator.sample(100)\n",
    "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
    "\n",
    "    for d_step in range(d_steps):\n",
    "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
    "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
    "        for epoch in range(epochs):\n",
    "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
    "            sys.stdout.flush()\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "\n",
    "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
    "                dis_opt.zero_grad()\n",
    "                out = discriminator.batchClassify(inp)\n",
    "                loss_fn = nn.BCELoss()\n",
    "                loss = loss_fn(out, target)\n",
    "                loss.backward()\n",
    "                dis_opt.step()\n",
    "\n",
    "                total_loss += loss.data.item()\n",
    "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
    "                print(out.size())\n",
    "                print(((out>0.5)==(target>0.5)).size())\n",
    "                print(total_acc)\n",
    "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
    "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                    print('.', end='')\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
    "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
    "\n",
    "            val_pred = discriminator.batchClassify(val_inp)\n",
    "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
    "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/200.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 1 epoch 1 : torch.Size([32])\n",
      "torch.Size([32])\n",
      "32\n",
      ".torch.Size([32])\n",
      "torch.Size([32])\n",
      "64\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "96\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "128\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "160\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "192\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "224\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "256\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "288\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "320\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "352\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "383\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "415\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "447\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "479\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "511\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "543\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "575\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "606\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "638\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "670\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "701\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "732\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "764\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "796\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "828\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "860\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "891\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "923\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "955\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "987\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1019\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1050\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1080\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1112\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1144\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1176\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1207\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1239\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1270\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1302\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1334\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1366\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1398\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1430\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1462\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1493\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1525\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1557\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1589\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1621\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1653\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1685\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1717\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1749\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1781\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1813\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1845\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1877\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1909\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1941\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "1973\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2005\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2037\n",
      ".torch.Size([32])\n",
      "torch.Size([32])\n",
      "2068\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2100\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2132\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2164\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2196\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2228\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2260\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2292\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2324\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2356\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2387\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2419\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2451\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2483\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2515\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2547\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2579\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2611\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2641\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2673\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2705\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2737\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2769\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2801\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2833\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2864\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2896\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2928\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2959\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "2991\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3022\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3054\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3085\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3116\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3148\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3180\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3212\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3244\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3276\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3307\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3339\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3370\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3402\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3434\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3465\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3497\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3529\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3560\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3592\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3624\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3656\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3688\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3720\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3752\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3784\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3815\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3847\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3879\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3910\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3942\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "3974\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4006\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4038\n",
      ".torch.Size([32])\n",
      "torch.Size([32])\n",
      "4070\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4102\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4134\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4166\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4198\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4230\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4261\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4292\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4324\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4356\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4388\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4420\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4451\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4483\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4515\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4547\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4579\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4611\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4643\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4675\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4707\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4739\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4769\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4801\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4833\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4865\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4897\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4929\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4961\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "4993\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5025\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5057\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5089\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5121\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5152\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5183\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5215\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5247\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5279\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5311\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5343\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5375\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5407\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5439\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5471\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5503\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5532\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5564\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5595\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5627\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5658\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5690\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5722\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5754\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5785\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5817\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5849\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5881\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5912\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5944\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "5976\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6008\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6040\n",
      ".torch.Size([32])\n",
      "torch.Size([32])\n",
      "6072\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6104\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6136\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6168\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6199\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6231\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6263\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6294\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6326\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6357\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6389\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6421\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6453\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6485\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6517\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6549\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6581\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6613\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6645\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6677\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6709\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6741\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6773\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6805\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6837\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6869\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6901\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6933\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6965\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "6997\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7029\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7061\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7093\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7125\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7157\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7188\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7220\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7252\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7284\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7316\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7347\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7378\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7410\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7442\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7474\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7506\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7538\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7570\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7601\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7633\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7665\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7696\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7727\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7759\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7790\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7822\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7854\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7886\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7918\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7950\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "7982\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8012\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8044\n",
      ".torch.Size([32])\n",
      "torch.Size([32])\n",
      "8076\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8108\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8140\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8172\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8204\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8236\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8268\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8299\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8330\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8362\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8393\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8424\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8456\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8488\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8520\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8552\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8584\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8616\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8648\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8680\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8712\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8744\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8776\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8807\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8839\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8871\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8903\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8935\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8967\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "8999\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9031\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9063\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9095\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9127\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9159\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9191\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9223\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9255\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9287\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9319\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9351\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9383\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9415\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9447\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9479\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9511\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9543\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9575\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9607\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9638\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9670\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9702\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9734\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9765\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9797\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9829\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9861\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9893\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9925\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9957\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "9989\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10021\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10053\n",
      ".torch.Size([32])\n",
      "torch.Size([32])\n",
      "10085\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10117\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10149\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10181\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10212\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10244\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10275\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10307\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10339\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10371\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10403\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10435\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10464\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10496\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10528\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10559\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10591\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10623\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10655\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10686\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10718\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10750\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10782\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10814\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10846\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10878\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10910\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10942\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "10974\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "11005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8aeee91ebbc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9cffc01286d8>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(discriminator, dis_opt, real_data_samples, generator, oracle, d_steps, epochs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mdis_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_values\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n",
      "epoch 1 : .......... average_train_NLL = 6.8112, oracle_sample_NLL = 14.7055\n",
      "epoch 2 : .......... average_train_NLL = 6.1624, oracle_sample_NLL = 13.6573\n",
      "epoch 3 : .......... average_train_NLL = 5.8390, oracle_sample_NLL = 13.1075\n",
      "epoch 4 : .......... average_train_NLL = 5.6311, oracle_sample_NLL = 12.7521\n",
      "epoch 5 : .......... average_train_NLL = 5.4814, oracle_sample_NLL = 12.4448\n",
      "epoch 6 : .......... average_train_NLL = 5.3692, oracle_sample_NLL = 12.2441\n",
      "epoch 7 : .......... average_train_NLL = 5.2807, oracle_sample_NLL = 12.0314\n",
      "epoch 8 : .......... average_train_NLL = 5.2091, oracle_sample_NLL = 11.9553\n",
      "epoch 9 : .......... average_train_NLL = 5.1495, oracle_sample_NLL = 11.8170\n",
      "epoch 10 : .......... average_train_NLL = 5.0988, oracle_sample_NLL = 11.7294\n",
      "epoch 11 : .......... average_train_NLL = 5.0554, oracle_sample_NLL = 11.6184\n",
      "epoch 12 : .......... average_train_NLL = 5.0172, oracle_sample_NLL = 11.5857\n",
      "epoch 13 : .......... average_train_NLL = 4.9837, oracle_sample_NLL = 11.4814\n",
      "epoch 14 : .......... average_train_NLL = 4.9538, oracle_sample_NLL = 11.4512\n",
      "epoch 15 : .......... average_train_NLL = 4.9275, oracle_sample_NLL = 11.3887\n",
      "epoch 16 : .......... average_train_NLL = 4.9039, oracle_sample_NLL = 11.3714\n",
      "epoch 17 : .......... average_train_NLL = 4.8824, oracle_sample_NLL = 11.3329\n",
      "epoch 18 : .......... average_train_NLL = 4.8628, oracle_sample_NLL = 11.2768\n",
      "epoch 19 : .......... average_train_NLL = 4.8443, oracle_sample_NLL = 11.2809\n",
      "epoch 20 : .......... average_train_NLL = 4.8285, oracle_sample_NLL = 11.2851\n",
      "epoch 21 : .......... average_train_NLL = 4.8129, oracle_sample_NLL = 11.2103\n",
      "epoch 22 : .......... average_train_NLL = 4.7992, oracle_sample_NLL = 11.1874\n",
      "epoch 23 : .......... average_train_NLL = 4.7891, oracle_sample_NLL = 11.1802\n",
      "epoch 24 : .......... average_train_NLL = 4.7736, oracle_sample_NLL = 11.1630\n",
      "epoch 25 : .......... average_train_NLL = 4.7621, oracle_sample_NLL = 11.1870\n",
      "epoch 26 : .......... average_train_NLL = 4.7542, oracle_sample_NLL = 11.1243\n",
      "epoch 27 : .......... average_train_NLL = 4.7436, oracle_sample_NLL = 11.1387\n",
      "epoch 28 : .......... average_train_NLL = 4.7329, oracle_sample_NLL = 11.0971\n",
      "epoch 29 : .......... average_train_NLL = 4.7246, oracle_sample_NLL = 11.1292\n",
      "epoch 30 : .......... average_train_NLL = 4.7180, oracle_sample_NLL = 11.1116\n",
      "epoch 31 : .......... average_train_NLL = 4.7104, oracle_sample_NLL = 11.1562\n",
      "epoch 32 : .......... average_train_NLL = 4.7041, oracle_sample_NLL = 11.1226\n",
      "epoch 33 : .......... average_train_NLL = 4.6985, oracle_sample_NLL = 11.1287\n",
      "epoch 34 : .......... average_train_NLL = 4.6914, oracle_sample_NLL = 11.1066\n",
      "epoch 35 : .......... average_train_NLL = 4.6827, oracle_sample_NLL = 11.0911\n",
      "epoch 36 : .......... average_train_NLL = 4.6762, oracle_sample_NLL = 11.0917\n",
      "epoch 37 : .......... average_train_NLL = 4.6708, oracle_sample_NLL = 11.0622\n",
      "epoch 38 : .......... average_train_NLL = 4.6654, oracle_sample_NLL = 11.0763\n",
      "epoch 39 : .......... average_train_NLL = 4.6601, oracle_sample_NLL = 11.0696\n",
      "epoch 40 : .......... average_train_NLL = 4.6566, oracle_sample_NLL = 11.0449\n",
      "epoch 41 : .......... average_train_NLL = 4.6526, oracle_sample_NLL = 11.0322\n",
      "epoch 42 : .......... average_train_NLL = 4.6471, oracle_sample_NLL = 11.0269\n",
      "epoch 43 : .......... average_train_NLL = 4.6425, oracle_sample_NLL = 11.0468\n",
      "epoch 44 : .......... average_train_NLL = 4.6366, oracle_sample_NLL = 10.9987\n",
      "epoch 45 : .......... average_train_NLL = 4.6344, oracle_sample_NLL = 11.0552\n",
      "epoch 46 : .......... average_train_NLL = 4.6289, oracle_sample_NLL = 11.0687\n",
      "epoch 47 : .......... average_train_NLL = 4.6290, oracle_sample_NLL = 11.0466\n",
      "epoch 48 : .......... average_train_NLL = 4.6219, oracle_sample_NLL = 11.0349\n",
      "epoch 49 : .......... average_train_NLL = 4.6212, oracle_sample_NLL = 11.0226\n",
      "epoch 50 : .......... average_train_NLL = 4.6132, oracle_sample_NLL = 11.0335\n",
      "epoch 51 : .......... average_train_NLL = 4.6123, oracle_sample_NLL = 10.9649\n",
      "epoch 52 : .......... average_train_NLL = 4.6074, oracle_sample_NLL = 10.9574\n",
      "epoch 53 : .......... average_train_NLL = 4.6008, oracle_sample_NLL = 11.0064\n",
      "epoch 54 : .......... average_train_NLL = 4.6031, oracle_sample_NLL = 11.0397\n",
      "epoch 55 : .......... average_train_NLL = 4.5985, oracle_sample_NLL = 11.0289\n",
      "epoch 56 : .......... average_train_NLL = 4.5924, oracle_sample_NLL = 10.9595\n",
      "epoch 57 : .......... average_train_NLL = 4.5902, oracle_sample_NLL = 10.9846\n",
      "epoch 58 : .......... average_train_NLL = 4.5910, oracle_sample_NLL = 10.9965\n",
      "epoch 59 : .......... average_train_NLL = 4.5921, oracle_sample_NLL = 11.0002\n",
      "epoch 60 : .......... average_train_NLL = 4.5834, oracle_sample_NLL = 10.9486\n",
      "epoch 61 : .......... average_train_NLL = 4.5796, oracle_sample_NLL = 10.9604\n",
      "epoch 62 : .......... average_train_NLL = 4.5786, oracle_sample_NLL = 10.9575\n",
      "epoch 63 : .......... average_train_NLL = 4.5786, oracle_sample_NLL = 10.9639\n",
      "epoch 64 : .......... average_train_NLL = 4.5736, oracle_sample_NLL = 10.9541\n",
      "epoch 65 : .......... average_train_NLL = 4.5708, oracle_sample_NLL = 10.9174\n",
      "epoch 66 : .......... average_train_NLL = 4.5675, oracle_sample_NLL = 10.9523\n",
      "epoch 67 : .......... average_train_NLL = 4.5699, oracle_sample_NLL = 10.9704\n",
      "epoch 68 : .......... average_train_NLL = 4.5699, oracle_sample_NLL = 10.9462\n",
      "epoch 69 : .......... average_train_NLL = 4.5652, oracle_sample_NLL = 10.9816\n",
      "epoch 70 : .......... average_train_NLL = 4.5633, oracle_sample_NLL = 10.9880\n",
      "epoch 71 : .......... average_train_NLL = 4.5615, oracle_sample_NLL = 10.9073\n",
      "epoch 72 : .......... average_train_NLL = 4.5597, oracle_sample_NLL = 10.9563\n",
      "epoch 73 : .......... average_train_NLL = 4.5586, oracle_sample_NLL = 10.8904\n",
      "epoch 74 : .......... average_train_NLL = 4.5578, oracle_sample_NLL = 10.9283\n",
      "epoch 75 : .......... average_train_NLL = 4.5535, oracle_sample_NLL = 10.9854\n",
      "epoch 76 : .......... average_train_NLL = 4.5492, oracle_sample_NLL = 10.9359\n",
      "epoch 77 : .......... average_train_NLL = 4.5487, oracle_sample_NLL = 10.8736\n",
      "epoch 78 : .......... average_train_NLL = 4.5497, oracle_sample_NLL = 10.9147\n",
      "epoch 79 : .......... average_train_NLL = 4.5445, oracle_sample_NLL = 10.9393\n",
      "epoch 80 : .......... average_train_NLL = 4.5557, oracle_sample_NLL = 10.9265\n",
      "epoch 81 : .......... average_train_NLL = 4.5465, oracle_sample_NLL = 10.9190\n",
      "epoch 82 : .......... average_train_NLL = 4.5419, oracle_sample_NLL = 10.9078\n",
      "epoch 83 : .......... average_train_NLL = 4.5422, oracle_sample_NLL = 10.9334\n",
      "epoch 84 : .......... average_train_NLL = 4.5369, oracle_sample_NLL = 10.9145\n",
      "epoch 85 : .......... average_train_NLL = 4.5414, oracle_sample_NLL = 10.9375\n",
      "epoch 86 : .......... average_train_NLL = 4.5379, oracle_sample_NLL = 10.9533\n",
      "epoch 87 : .......... average_train_NLL = 4.5370, oracle_sample_NLL = 10.9580\n",
      "epoch 88 : .......... average_train_NLL = 4.5391, oracle_sample_NLL = 10.9201\n",
      "epoch 89 : .......... average_train_NLL = 4.5320, oracle_sample_NLL = 10.9023\n",
      "epoch 90 : .......... average_train_NLL = 4.5285, oracle_sample_NLL = 10.9590\n",
      "epoch 91 : .......... average_train_NLL = 4.5312, oracle_sample_NLL = 10.9605\n",
      "epoch 92 : .......... average_train_NLL = 4.5316, oracle_sample_NLL = 10.9617\n",
      "epoch 93 : .......... average_train_NLL = 4.5335, oracle_sample_NLL = 10.8089\n",
      "epoch 94 : .......... average_train_NLL = 4.5336, oracle_sample_NLL = 10.8928\n",
      "epoch 95 : .......... average_train_NLL = 4.5217, oracle_sample_NLL = 10.9283\n",
      "epoch 96 : .......... average_train_NLL = 4.5266, oracle_sample_NLL = 10.9004\n",
      "epoch 97 : .......... average_train_NLL = 4.5306, oracle_sample_NLL = 10.9162\n",
      "epoch 98 : .......... average_train_NLL = 4.5259, oracle_sample_NLL = 10.8926\n",
      "epoch 99 : .......... average_train_NLL = 4.5266, oracle_sample_NLL = 10.8740\n",
      "epoch 100 : .......... average_train_NLL = 4.5192, oracle_sample_NLL = 10.8983\n",
      "\n",
      "Starting Discriminator Training...\n",
      "d-step 1 epoch 1 : .......... average_loss = 0.6838, train_acc = 0.5554, val_acc = 0.6150\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.6530, train_acc = 0.6145, val_acc = 0.6450\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.6226, train_acc = 0.6551, val_acc = 0.6600\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.6279, train_acc = 0.6485, val_acc = 0.6050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.6013, train_acc = 0.6772, val_acc = 0.6000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.5739, train_acc = 0.7060, val_acc = 0.6450\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.5844, train_acc = 0.6916, val_acc = 0.6250\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.5590, train_acc = 0.7156, val_acc = 0.6250\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.5331, train_acc = 0.7350, val_acc = 0.6350\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.5513, train_acc = 0.7238, val_acc = 0.6500\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.5231, train_acc = 0.7431, val_acc = 0.6800\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.4986, train_acc = 0.7597, val_acc = 0.6500\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.5170, train_acc = 0.7504, val_acc = 0.6550\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.4892, train_acc = 0.7683, val_acc = 0.6400\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.4620, train_acc = 0.7872, val_acc = 0.6900\n",
      "d-step 6 epoch 1 : .......... average_loss = 0.4798, train_acc = 0.7760, val_acc = 0.6850\n",
      "d-step 6 epoch 2 : .......... average_loss = 0.4494, train_acc = 0.7975, val_acc = 0.6550\n",
      "d-step 6 epoch 3 : .......... average_loss = 0.4224, train_acc = 0.8138, val_acc = 0.6550\n",
      "d-step 7 epoch 1 : .......... average_loss = 0.4517, train_acc = 0.7950, val_acc = 0.6450\n",
      "d-step 7 epoch 2 : .......... average_loss = 0.4210, train_acc = 0.8114, val_acc = 0.6500\n",
      "d-step 7 epoch 3 : .......... average_loss = 0.3948, train_acc = 0.8290, val_acc = 0.6550\n",
      "d-step 8 epoch 1 : .......... average_loss = 0.4221, train_acc = 0.8134, val_acc = 0.6750\n",
      "d-step 8 epoch 2 : .......... average_loss = 0.3911, train_acc = 0.8315, val_acc = 0.6800\n",
      "d-step 8 epoch 3 : .......... average_loss = 0.3636, train_acc = 0.8466, val_acc = 0.6650\n",
      "d-step 9 epoch 1 : .......... average_loss = 0.3953, train_acc = 0.8301, val_acc = 0.6550\n",
      "d-step 9 epoch 2 : .......... average_loss = 0.3637, train_acc = 0.8487, val_acc = 0.6650\n",
      "d-step 9 epoch 3 : .......... average_loss = 0.3373, train_acc = 0.8588, val_acc = 0.6400\n",
      "d-step 10 epoch 1 : .......... average_loss = 0.3730, train_acc = 0.8444, val_acc = 0.6550\n",
      "d-step 10 epoch 2 : .......... average_loss = 0.3400, train_acc = 0.8625, val_acc = 0.6650\n",
      "d-step 10 epoch 3 : .......... average_loss = 0.3137, train_acc = 0.8783, val_acc = 0.6600\n",
      "d-step 11 epoch 1 : .......... average_loss = 0.3430, train_acc = 0.8615, val_acc = 0.6600\n",
      "d-step 11 epoch 2 : .......... average_loss = 0.3131, train_acc = 0.8794, val_acc = 0.6700\n",
      "d-step 11 epoch 3 : .......... average_loss = 0.2867, train_acc = 0.8901, val_acc = 0.6500\n",
      "d-step 12 epoch 1 : .......... average_loss = 0.3261, train_acc = 0.8721, val_acc = 0.6300\n",
      "d-step 12 epoch 2 : .......... average_loss = 0.2932, train_acc = 0.8898, val_acc = 0.6550\n",
      "d-step 12 epoch 3 : .......... average_loss = 0.2691, train_acc = 0.9026, val_acc = 0.6250\n",
      "d-step 13 epoch 1 : .......... average_loss = 0.3121, train_acc = 0.8829, val_acc = 0.6400\n",
      "d-step 13 epoch 2 : .......... average_loss = 0.2785, train_acc = 0.8985, val_acc = 0.6450\n",
      "d-step 13 epoch 3 : .......... average_loss = 0.2546, train_acc = 0.9076, val_acc = 0.6200\n",
      "d-step 14 epoch 1 : .......... average_loss = 0.2975, train_acc = 0.8902, val_acc = 0.6600\n",
      "d-step 14 epoch 2 : .......... average_loss = 0.2651, train_acc = 0.9055, val_acc = 0.6500\n",
      "d-step 14 epoch 3 : .......... average_loss = 0.2414, train_acc = 0.9190, val_acc = 0.6650\n",
      "d-step 15 epoch 1 : .......... average_loss = 0.2649, train_acc = 0.9044, val_acc = 0.6400\n",
      "d-step 15 epoch 2 : .......... average_loss = 0.2400, train_acc = 0.9154, val_acc = 0.6400\n",
      "d-step 15 epoch 3 : .......... average_loss = 0.2148, train_acc = 0.9274, val_acc = 0.6450\n",
      "d-step 16 epoch 1 : .......... average_loss = 0.2643, train_acc = 0.9086, val_acc = 0.6650\n",
      "d-step 16 epoch 2 : .......... average_loss = 0.2317, train_acc = 0.9223, val_acc = 0.6350\n",
      "d-step 16 epoch 3 : .......... average_loss = 0.2070, train_acc = 0.9313, val_acc = 0.6450\n",
      "d-step 17 epoch 1 : .......... average_loss = 0.2490, train_acc = 0.9182, val_acc = 0.6300\n",
      "d-step 17 epoch 2 : .......... average_loss = 0.2241, train_acc = 0.9274, val_acc = 0.6400\n",
      "d-step 17 epoch 3 : .......... average_loss = 0.1956, train_acc = 0.9373, val_acc = 0.6300\n",
      "d-step 18 epoch 1 : .......... average_loss = 0.2351, train_acc = 0.9241, val_acc = 0.6500\n",
      "d-step 18 epoch 2 : .......... average_loss = 0.2105, train_acc = 0.9315, val_acc = 0.6300\n",
      "d-step 18 epoch 3 : .......... average_loss = 0.1867, train_acc = 0.9413, val_acc = 0.6450\n",
      "d-step 19 epoch 1 : .......... average_loss = 0.2198, train_acc = 0.9296, val_acc = 0.6350\n",
      "d-step 19 epoch 2 : .......... average_loss = 0.1919, train_acc = 0.9405, val_acc = 0.6300\n",
      "d-step 19 epoch 3 : .......... average_loss = 0.1704, train_acc = 0.9466, val_acc = 0.6150\n",
      "d-step 20 epoch 1 : .......... average_loss = 0.2146, train_acc = 0.9307, val_acc = 0.6250\n",
      "d-step 20 epoch 2 : .......... average_loss = 0.1880, train_acc = 0.9431, val_acc = 0.6250\n",
      "d-step 20 epoch 3 : .......... average_loss = 0.1639, train_acc = 0.9513, val_acc = 0.6200\n",
      "d-step 21 epoch 1 : .......... average_loss = 0.2009, train_acc = 0.9390, val_acc = 0.6350\n",
      "d-step 21 epoch 2 : .......... average_loss = 0.1745, train_acc = 0.9464, val_acc = 0.6350\n",
      "d-step 21 epoch 3 : .......... average_loss = 0.1541, train_acc = 0.9551, val_acc = 0.6300\n",
      "d-step 22 epoch 1 : .......... average_loss = 0.1930, train_acc = 0.9395, val_acc = 0.6150\n",
      "d-step 22 epoch 2 : .......... average_loss = 0.1682, train_acc = 0.9479, val_acc = 0.6400\n",
      "d-step 22 epoch 3 : .......... average_loss = 0.1475, train_acc = 0.9562, val_acc = 0.6150\n",
      "d-step 23 epoch 1 : .......... average_loss = 0.1967, train_acc = 0.9411, val_acc = 0.6350\n",
      "d-step 23 epoch 2 : .......... average_loss = 0.1681, train_acc = 0.9495, val_acc = 0.6300\n",
      "d-step 23 epoch 3 : .......... average_loss = 0.1468, train_acc = 0.9567, val_acc = 0.6300\n",
      "d-step 24 epoch 1 : .......... average_loss = 0.1855, train_acc = 0.9440, val_acc = 0.6200\n",
      "d-step 24 epoch 2 : .......... average_loss = 0.1613, train_acc = 0.9517, val_acc = 0.6350\n",
      "d-step 24 epoch 3 : .......... average_loss = 0.1387, train_acc = 0.9606, val_acc = 0.6300\n",
      "d-step 25 epoch 1 : .......... average_loss = 0.1834, train_acc = 0.9459, val_acc = 0.6300\n",
      "d-step 25 epoch 2 : .......... average_loss = 0.1587, train_acc = 0.9558, val_acc = 0.6150\n",
      "d-step 25 epoch 3 : .......... average_loss = 0.1389, train_acc = 0.9610, val_acc = 0.6350\n",
      "d-step 26 epoch 1 : .......... average_loss = 0.1705, train_acc = 0.9497, val_acc = 0.6250\n",
      "d-step 26 epoch 2 : .......... average_loss = 0.1449, train_acc = 0.9585, val_acc = 0.6350\n",
      "d-step 26 epoch 3 : .......... average_loss = 0.1267, train_acc = 0.9659, val_acc = 0.6350\n",
      "d-step 27 epoch 1 : .......... average_loss = 0.1718, train_acc = 0.9503, val_acc = 0.6150\n",
      "d-step 27 epoch 2 : .......... average_loss = 0.1470, train_acc = 0.9595, val_acc = 0.6300\n",
      "d-step 27 epoch 3 : .......... average_loss = 0.1276, train_acc = 0.9657, val_acc = 0.6350\n",
      "d-step 28 epoch 1 : .......... average_loss = 0.1689, train_acc = 0.9521, val_acc = 0.6500\n",
      "d-step 28 epoch 2 : .......... average_loss = 0.1430, train_acc = 0.9609, val_acc = 0.6450\n",
      "d-step 28 epoch 3 : .......... average_loss = 0.1293, train_acc = 0.9656, val_acc = 0.6250\n",
      "d-step 29 epoch 1 : .......... average_loss = 0.1567, train_acc = 0.9568, val_acc = 0.6200\n",
      "d-step 29 epoch 2 : .......... average_loss = 0.1332, train_acc = 0.9639, val_acc = 0.6250\n",
      "d-step 29 epoch 3 : .......... average_loss = 0.1164, train_acc = 0.9687, val_acc = 0.6400\n",
      "d-step 30 epoch 1 : .......... average_loss = 0.1512, train_acc = 0.9596, val_acc = 0.6150\n",
      "d-step 30 epoch 2 : .......... average_loss = 0.1300, train_acc = 0.9645, val_acc = 0.6300\n",
      "d-step 30 epoch 3 : .......... average_loss = 0.1118, train_acc = 0.9697, val_acc = 0.6300\n",
      "d-step 31 epoch 1 : .......... average_loss = 0.1444, train_acc = 0.9598, val_acc = 0.6150\n",
      "d-step 31 epoch 2 : .......... average_loss = 0.1240, train_acc = 0.9682, val_acc = 0.6350\n",
      "d-step 31 epoch 3 : .......... average_loss = 0.1070, train_acc = 0.9718, val_acc = 0.6350\n",
      "d-step 32 epoch 1 : .......... average_loss = 0.1490, train_acc = 0.9600, val_acc = 0.6400\n",
      "d-step 32 epoch 2 : .......... average_loss = 0.1273, train_acc = 0.9664, val_acc = 0.6100\n",
      "d-step 32 epoch 3 : .......... average_loss = 0.1089, train_acc = 0.9717, val_acc = 0.6050\n",
      "d-step 33 epoch 1 : .......... average_loss = 0.1429, train_acc = 0.9599, val_acc = 0.6300\n",
      "d-step 33 epoch 2 : .......... average_loss = 0.1216, train_acc = 0.9667, val_acc = 0.6300\n",
      "d-step 33 epoch 3 : .......... average_loss = 0.1057, train_acc = 0.9711, val_acc = 0.6350\n",
      "d-step 34 epoch 1 : .......... average_loss = 0.1405, train_acc = 0.9623, val_acc = 0.6200\n",
      "d-step 34 epoch 2 : .......... average_loss = 0.1136, train_acc = 0.9704, val_acc = 0.6200\n",
      "d-step 34 epoch 3 : .......... average_loss = 0.1001, train_acc = 0.9734, val_acc = 0.6300\n",
      "d-step 35 epoch 1 : .......... average_loss = 0.1372, train_acc = 0.9633, val_acc = 0.6000\n",
      "d-step 35 epoch 2 : .......... average_loss = 0.1128, train_acc = 0.9697, val_acc = 0.6200\n",
      "d-step 35 epoch 3 : .......... average_loss = 0.0968, train_acc = 0.9745, val_acc = 0.6250\n",
      "d-step 36 epoch 1 : .......... average_loss = 0.1318, train_acc = 0.9643, val_acc = 0.6150\n",
      "d-step 36 epoch 2 : .......... average_loss = 0.1090, train_acc = 0.9713, val_acc = 0.6150\n",
      "d-step 36 epoch 3 : .......... average_loss = 0.0951, train_acc = 0.9744, val_acc = 0.6250\n",
      "d-step 37 epoch 1 : .......... average_loss = 0.1310, train_acc = 0.9657, val_acc = 0.6450\n",
      "d-step 37 epoch 2 : .......... average_loss = 0.1082, train_acc = 0.9727, val_acc = 0.6250\n",
      "d-step 37 epoch 3 : .......... average_loss = 0.0938, train_acc = 0.9764, val_acc = 0.6300\n",
      "d-step 38 epoch 1 : .......... average_loss = 0.1282, train_acc = 0.9662, val_acc = 0.6150\n",
      "d-step 38 epoch 2 : .......... average_loss = 0.1067, train_acc = 0.9732, val_acc = 0.6200\n",
      "d-step 38 epoch 3 : .......... average_loss = 0.0918, train_acc = 0.9765, val_acc = 0.6200\n",
      "d-step 39 epoch 1 : .......... average_loss = 0.1266, train_acc = 0.9667, val_acc = 0.6300\n",
      "d-step 39 epoch 2 : .......... average_loss = 0.1048, train_acc = 0.9732, val_acc = 0.6300\n",
      "d-step 39 epoch 3 : .......... average_loss = 0.0904, train_acc = 0.9760, val_acc = 0.6200\n",
      "d-step 40 epoch 1 : .......... average_loss = 0.1272, train_acc = 0.9666, val_acc = 0.6100\n",
      "d-step 40 epoch 2 : .......... average_loss = 0.1062, train_acc = 0.9730, val_acc = 0.6200\n",
      "d-step 40 epoch 3 : .......... average_loss = 0.0915, train_acc = 0.9781, val_acc = 0.6050\n",
      "d-step 41 epoch 1 : .......... average_loss = 0.1293, train_acc = 0.9674, val_acc = 0.6300\n",
      "d-step 41 epoch 2 : .......... average_loss = 0.1075, train_acc = 0.9735, val_acc = 0.6300\n",
      "d-step 41 epoch 3 : .......... average_loss = 0.0935, train_acc = 0.9772, val_acc = 0.6250\n",
      "d-step 42 epoch 1 : .......... average_loss = 0.1175, train_acc = 0.9698, val_acc = 0.6200\n",
      "d-step 42 epoch 2 : .......... average_loss = 0.0954, train_acc = 0.9750, val_acc = 0.6000\n",
      "d-step 42 epoch 3 : .......... average_loss = 0.0813, train_acc = 0.9789, val_acc = 0.6400\n",
      "d-step 43 epoch 1 : .......... average_loss = 0.1149, train_acc = 0.9711, val_acc = 0.6150\n",
      "d-step 43 epoch 2 : .......... average_loss = 0.0941, train_acc = 0.9750, val_acc = 0.6150\n",
      "d-step 43 epoch 3 : .......... average_loss = 0.0796, train_acc = 0.9800, val_acc = 0.6250\n",
      "d-step 44 epoch 1 : .......... average_loss = 0.1247, train_acc = 0.9696, val_acc = 0.6350\n",
      "d-step 44 epoch 2 : .......... average_loss = 0.1047, train_acc = 0.9747, val_acc = 0.5950\n",
      "d-step 44 epoch 3 : .......... average_loss = 0.0893, train_acc = 0.9791, val_acc = 0.6300\n",
      "d-step 45 epoch 1 : .......... average_loss = 0.1126, train_acc = 0.9726, val_acc = 0.6200\n",
      "d-step 45 epoch 2 : .......... average_loss = 0.0972, train_acc = 0.9761, val_acc = 0.6050\n",
      "d-step 45 epoch 3 : .......... average_loss = 0.0842, train_acc = 0.9800, val_acc = 0.5900\n",
      "d-step 46 epoch 1 : .......... average_loss = 0.1124, train_acc = 0.9725, val_acc = 0.6150\n",
      "d-step 46 epoch 2 : .......... average_loss = 0.0943, train_acc = 0.9771, val_acc = 0.6050\n",
      "d-step 46 epoch 3 : .......... average_loss = 0.0804, train_acc = 0.9804, val_acc = 0.6300\n",
      "d-step 47 epoch 1 : .......... average_loss = 0.1044, train_acc = 0.9739, val_acc = 0.6300\n",
      "d-step 47 epoch 2 : .......... average_loss = 0.0872, train_acc = 0.9770, val_acc = 0.6100\n",
      "d-step 47 epoch 3 : .......... average_loss = 0.0728, train_acc = 0.9813, val_acc = 0.6050\n",
      "d-step 48 epoch 1 : .......... average_loss = 0.1069, train_acc = 0.9737, val_acc = 0.6200\n",
      "d-step 48 epoch 2 : .......... average_loss = 0.0897, train_acc = 0.9767, val_acc = 0.6300\n",
      "d-step 48 epoch 3 : .......... average_loss = 0.0748, train_acc = 0.9805, val_acc = 0.6300\n",
      "d-step 49 epoch 1 : .......... average_loss = 0.1066, train_acc = 0.9735, val_acc = 0.6100\n",
      "d-step 49 epoch 2 : .......... average_loss = 0.0879, train_acc = 0.9781, val_acc = 0.6100\n",
      "d-step 49 epoch 3 : .......... average_loss = 0.0768, train_acc = 0.9807, val_acc = 0.6000\n",
      "d-step 50 epoch 1 : .......... average_loss = 0.1093, train_acc = 0.9719, val_acc = 0.6300\n",
      "d-step 50 epoch 2 : .......... average_loss = 0.0854, train_acc = 0.9780, val_acc = 0.6300\n",
      "d-step 50 epoch 3 : .......... average_loss = 0.0705, train_acc = 0.9825, val_acc = 0.6350\n"
     ]
    }
   ],
   "source": [
    "    oracle = generator.Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "    oracle.load_state_dict(torch.load(oracle_state_dict_path))\n",
    "    oracle_samples = torch.load(oracle_samples_path).type(torch.LongTensor)\n",
    "    # a new oracle can be generated by passing oracle_init=True in the generator constructor\n",
    "    # samples for the new oracle can be generated using helpers.batchwise_sample()\n",
    "\n",
    "    gen = generator.Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "    dis = discriminator.Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "\n",
    "    if CUDA:\n",
    "        oracle = oracle.cuda()\n",
    "        gen = gen.cuda()\n",
    "        dis = dis.cuda()\n",
    "        oracle_samples = oracle_samples.cuda()\n",
    "\n",
    "    # GENERATOR MLE TRAINING\n",
    "    print('Starting Generator MLE Training...')\n",
    "    gen_optimizer = optim.Adam(gen.parameters(), lr=1e-2)\n",
    "    train_generator_MLE(gen, gen_optimizer, oracle, oracle_samples, MLE_TRAIN_EPOCHS)\n",
    "\n",
    "    # torch.save(gen.state_dict(), pretrained_gen_path)\n",
    "    # gen.load_state_dict(torch.load(pretrained_gen_path))\n",
    "\n",
    "    # PRETRAIN DISCRIMINATOR\n",
    "    print('\\nStarting Discriminator Training...')\n",
    "    dis_optimizer = optim.Adagrad(dis.parameters())\n",
    "    train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, 50, 3)\n",
    "\n",
    "    # torch.save(dis.state_dict(), pretrained_dis_path)\n",
    "    # dis.load_state_dict(torch.load(pretrained_dis_path))\n",
    "\n",
    "    # ADVERSARIAL TRAINING\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Adversarial Training...\n",
      "\n",
      "Initial Oracle Sample Loss : 10.8424\n",
      "\n",
      "--------\n",
      "EPOCH 1\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.8539\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.1132, train_acc = 0.9730, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0915, train_acc = 0.9784, val_acc = 0.5950\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0811, train_acc = 0.9811, val_acc = 0.6200\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.1021, train_acc = 0.9752, val_acc = 0.6050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0871, train_acc = 0.9773, val_acc = 0.6000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0720, train_acc = 0.9828, val_acc = 0.6150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.1019, train_acc = 0.9748, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0838, train_acc = 0.9792, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0717, train_acc = 0.9829, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0945, train_acc = 0.9765, val_acc = 0.6000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0762, train_acc = 0.9809, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0644, train_acc = 0.9838, val_acc = 0.6100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0965, train_acc = 0.9768, val_acc = 0.6000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0778, train_acc = 0.9806, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0648, train_acc = 0.9839, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 2\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.8203\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0981, train_acc = 0.9771, val_acc = 0.5550\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0813, train_acc = 0.9808, val_acc = 0.5700\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0667, train_acc = 0.9849, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0978, train_acc = 0.9758, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0785, train_acc = 0.9816, val_acc = 0.5650\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0653, train_acc = 0.9846, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0955, train_acc = 0.9775, val_acc = 0.5700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0807, train_acc = 0.9815, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0664, train_acc = 0.9840, val_acc = 0.5750\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.1001, train_acc = 0.9764, val_acc = 0.5600\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0834, train_acc = 0.9803, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0723, train_acc = 0.9829, val_acc = 0.5700\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0942, train_acc = 0.9772, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0772, train_acc = 0.9811, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0654, train_acc = 0.9836, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 3\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.8112\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0948, train_acc = 0.9778, val_acc = 0.6250\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0766, train_acc = 0.9817, val_acc = 0.6300\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0625, train_acc = 0.9848, val_acc = 0.6150\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0937, train_acc = 0.9773, val_acc = 0.6200\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0757, train_acc = 0.9814, val_acc = 0.6200\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0641, train_acc = 0.9840, val_acc = 0.6200\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0851, train_acc = 0.9802, val_acc = 0.6300\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0671, train_acc = 0.9835, val_acc = 0.6300\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0583, train_acc = 0.9861, val_acc = 0.6300\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0827, train_acc = 0.9794, val_acc = 0.6350\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0676, train_acc = 0.9826, val_acc = 0.6250\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0566, train_acc = 0.9853, val_acc = 0.6500\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0891, train_acc = 0.9797, val_acc = 0.6250\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0722, train_acc = 0.9820, val_acc = 0.6250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0601, train_acc = 0.9858, val_acc = 0.6100\n",
      "\n",
      "--------\n",
      "EPOCH 4\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.7427\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0831, train_acc = 0.9800, val_acc = 0.5550\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0651, train_acc = 0.9842, val_acc = 0.5550\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0555, train_acc = 0.9866, val_acc = 0.5700\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0768, train_acc = 0.9811, val_acc = 0.5550\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0615, train_acc = 0.9859, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0535, train_acc = 0.9873, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0798, train_acc = 0.9810, val_acc = 0.5700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0650, train_acc = 0.9845, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0539, train_acc = 0.9877, val_acc = 0.5900\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0786, train_acc = 0.9808, val_acc = 0.5600\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0647, train_acc = 0.9846, val_acc = 0.5500\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0550, train_acc = 0.9859, val_acc = 0.5650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0768, train_acc = 0.9820, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0616, train_acc = 0.9847, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0509, train_acc = 0.9868, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 5\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.7288\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0752, train_acc = 0.9823, val_acc = 0.5800\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0605, train_acc = 0.9865, val_acc = 0.6100\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0505, train_acc = 0.9889, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0779, train_acc = 0.9824, val_acc = 0.5950\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0651, train_acc = 0.9855, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0521, train_acc = 0.9884, val_acc = 0.5900\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0873, train_acc = 0.9808, val_acc = 0.5750\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0705, train_acc = 0.9839, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0598, train_acc = 0.9870, val_acc = 0.5900\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0793, train_acc = 0.9813, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0646, train_acc = 0.9843, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0541, train_acc = 0.9872, val_acc = 0.5700\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0739, train_acc = 0.9817, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0609, train_acc = 0.9856, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0503, train_acc = 0.9877, val_acc = 0.5800\n",
      "\n",
      "--------\n",
      "EPOCH 6\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.6669\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0790, train_acc = 0.9815, val_acc = 0.6100\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0618, train_acc = 0.9849, val_acc = 0.6000\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0521, train_acc = 0.9877, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0752, train_acc = 0.9829, val_acc = 0.6100\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0619, train_acc = 0.9856, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0520, train_acc = 0.9876, val_acc = 0.6150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0711, train_acc = 0.9835, val_acc = 0.6150\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0556, train_acc = 0.9865, val_acc = 0.6100\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0464, train_acc = 0.9891, val_acc = 0.6200\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0716, train_acc = 0.9822, val_acc = 0.6150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0559, train_acc = 0.9867, val_acc = 0.6100\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0444, train_acc = 0.9904, val_acc = 0.6100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0760, train_acc = 0.9828, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0587, train_acc = 0.9870, val_acc = 0.6050\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0511, train_acc = 0.9880, val_acc = 0.6150\n",
      "\n",
      "--------\n",
      "EPOCH 7\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.6286\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0707, train_acc = 0.9842, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0569, train_acc = 0.9876, val_acc = 0.5950\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0483, train_acc = 0.9891, val_acc = 0.5850\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0734, train_acc = 0.9839, val_acc = 0.5900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0601, train_acc = 0.9860, val_acc = 0.5950\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0509, train_acc = 0.9880, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0709, train_acc = 0.9838, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0580, train_acc = 0.9866, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0475, train_acc = 0.9888, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0739, train_acc = 0.9836, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0606, train_acc = 0.9864, val_acc = 0.5900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0500, train_acc = 0.9887, val_acc = 0.5750\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0636, train_acc = 0.9856, val_acc = 0.6000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0504, train_acc = 0.9880, val_acc = 0.5900\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0430, train_acc = 0.9900, val_acc = 0.6050\n",
      "\n",
      "--------\n",
      "EPOCH 8\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.5977\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0638, train_acc = 0.9857, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0504, train_acc = 0.9885, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0426, train_acc = 0.9901, val_acc = 0.5850\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0632, train_acc = 0.9855, val_acc = 0.5900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0523, train_acc = 0.9879, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0424, train_acc = 0.9902, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0653, train_acc = 0.9856, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0548, train_acc = 0.9877, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0456, train_acc = 0.9897, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0698, train_acc = 0.9841, val_acc = 0.5950\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0573, train_acc = 0.9878, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0495, train_acc = 0.9891, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0622, train_acc = 0.9862, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0503, train_acc = 0.9883, val_acc = 0.5950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0403, train_acc = 0.9908, val_acc = 0.6050\n",
      "\n",
      "--------\n",
      "EPOCH 9\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.5419\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0626, train_acc = 0.9860, val_acc = 0.6200\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0504, train_acc = 0.9883, val_acc = 0.6150\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0412, train_acc = 0.9912, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0664, train_acc = 0.9858, val_acc = 0.6050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0534, train_acc = 0.9883, val_acc = 0.6100\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0443, train_acc = 0.9902, val_acc = 0.6250\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0562, train_acc = 0.9871, val_acc = 0.6150\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0461, train_acc = 0.9894, val_acc = 0.6050\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0387, train_acc = 0.9912, val_acc = 0.6150\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0550, train_acc = 0.9875, val_acc = 0.6200\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0440, train_acc = 0.9892, val_acc = 0.6200\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0349, train_acc = 0.9915, val_acc = 0.6150\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0626, train_acc = 0.9865, val_acc = 0.6150\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0492, train_acc = 0.9883, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0415, train_acc = 0.9911, val_acc = 0.6250\n",
      "\n",
      "--------\n",
      "EPOCH 10\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.5663\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0543, train_acc = 0.9873, val_acc = 0.6350\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0419, train_acc = 0.9896, val_acc = 0.6100\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0326, train_acc = 0.9925, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0617, train_acc = 0.9859, val_acc = 0.6150\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0484, train_acc = 0.9889, val_acc = 0.6250\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0396, train_acc = 0.9909, val_acc = 0.6300\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0656, train_acc = 0.9862, val_acc = 0.6350\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0525, train_acc = 0.9885, val_acc = 0.6200\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0420, train_acc = 0.9902, val_acc = 0.6200\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0624, train_acc = 0.9865, val_acc = 0.6400\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0479, train_acc = 0.9895, val_acc = 0.6400\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0392, train_acc = 0.9905, val_acc = 0.6300\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0624, train_acc = 0.9868, val_acc = 0.6300\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0519, train_acc = 0.9886, val_acc = 0.6300\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0419, train_acc = 0.9911, val_acc = 0.6300\n",
      "\n",
      "--------\n",
      "EPOCH 11\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.4788\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0606, train_acc = 0.9855, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0466, train_acc = 0.9882, val_acc = 0.6000\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0372, train_acc = 0.9919, val_acc = 0.5750\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0590, train_acc = 0.9877, val_acc = 0.5800\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0482, train_acc = 0.9893, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0368, train_acc = 0.9915, val_acc = 0.5800\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0603, train_acc = 0.9874, val_acc = 0.6000\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0510, train_acc = 0.9891, val_acc = 0.5950\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0411, train_acc = 0.9915, val_acc = 0.6050\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0559, train_acc = 0.9881, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0439, train_acc = 0.9899, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0371, train_acc = 0.9919, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0538, train_acc = 0.9886, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0433, train_acc = 0.9903, val_acc = 0.5800\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0368, train_acc = 0.9919, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 12\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.4238\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0550, train_acc = 0.9883, val_acc = 0.5500\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0438, train_acc = 0.9913, val_acc = 0.5550\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0365, train_acc = 0.9925, val_acc = 0.5600\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0498, train_acc = 0.9889, val_acc = 0.5600\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0412, train_acc = 0.9906, val_acc = 0.5300\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0328, train_acc = 0.9919, val_acc = 0.5350\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0551, train_acc = 0.9879, val_acc = 0.5500\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0442, train_acc = 0.9898, val_acc = 0.5500\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0355, train_acc = 0.9912, val_acc = 0.5550\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0556, train_acc = 0.9872, val_acc = 0.5450\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0438, train_acc = 0.9904, val_acc = 0.5650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0368, train_acc = 0.9918, val_acc = 0.5400\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0563, train_acc = 0.9865, val_acc = 0.5600\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0445, train_acc = 0.9896, val_acc = 0.5500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0355, train_acc = 0.9922, val_acc = 0.5600\n",
      "\n",
      "--------\n",
      "EPOCH 13\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.4498\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0512, train_acc = 0.9882, val_acc = 0.5800\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0426, train_acc = 0.9897, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0335, train_acc = 0.9926, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0558, train_acc = 0.9886, val_acc = 0.5900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0447, train_acc = 0.9907, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0372, train_acc = 0.9920, val_acc = 0.5900\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0498, train_acc = 0.9890, val_acc = 0.5850\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0391, train_acc = 0.9913, val_acc = 0.5950\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0331, train_acc = 0.9925, val_acc = 0.5900\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0519, train_acc = 0.9889, val_acc = 0.6050\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0422, train_acc = 0.9909, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0339, train_acc = 0.9927, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0571, train_acc = 0.9885, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0456, train_acc = 0.9905, val_acc = 0.5950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0381, train_acc = 0.9919, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 14\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.4349\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0555, train_acc = 0.9882, val_acc = 0.6150\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0450, train_acc = 0.9900, val_acc = 0.6150\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0367, train_acc = 0.9922, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0475, train_acc = 0.9895, val_acc = 0.6150\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0387, train_acc = 0.9909, val_acc = 0.6150\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0310, train_acc = 0.9931, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0484, train_acc = 0.9890, val_acc = 0.6200\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0386, train_acc = 0.9913, val_acc = 0.6250\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0299, train_acc = 0.9929, val_acc = 0.6050\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0543, train_acc = 0.9880, val_acc = 0.6100\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0418, train_acc = 0.9910, val_acc = 0.6100\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0342, train_acc = 0.9925, val_acc = 0.6050\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0479, train_acc = 0.9896, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0388, train_acc = 0.9910, val_acc = 0.6250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0293, train_acc = 0.9941, val_acc = 0.6300\n",
      "\n",
      "--------\n",
      "EPOCH 15\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.3754\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0562, train_acc = 0.9873, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0446, train_acc = 0.9899, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0367, train_acc = 0.9921, val_acc = 0.6050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0525, train_acc = 0.9885, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0399, train_acc = 0.9910, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0326, train_acc = 0.9918, val_acc = 0.5800\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0494, train_acc = 0.9893, val_acc = 0.5850\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0392, train_acc = 0.9915, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0307, train_acc = 0.9937, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0477, train_acc = 0.9899, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0360, train_acc = 0.9923, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0320, train_acc = 0.9923, val_acc = 0.5850\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0475, train_acc = 0.9899, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0381, train_acc = 0.9921, val_acc = 0.5950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0304, train_acc = 0.9936, val_acc = 0.5950\n",
      "\n",
      "--------\n",
      "EPOCH 16\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.3814\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0478, train_acc = 0.9893, val_acc = 0.5600\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0371, train_acc = 0.9908, val_acc = 0.5550\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0301, train_acc = 0.9925, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0431, train_acc = 0.9906, val_acc = 0.5600\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0326, train_acc = 0.9928, val_acc = 0.5600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0266, train_acc = 0.9941, val_acc = 0.5650\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0496, train_acc = 0.9893, val_acc = 0.5600\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0399, train_acc = 0.9913, val_acc = 0.5600\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0309, train_acc = 0.9925, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0483, train_acc = 0.9895, val_acc = 0.5450\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0387, train_acc = 0.9919, val_acc = 0.5550\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0314, train_acc = 0.9928, val_acc = 0.5600\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0401, train_acc = 0.9917, val_acc = 0.5600\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0323, train_acc = 0.9929, val_acc = 0.5800\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0253, train_acc = 0.9944, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 17\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.3480\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0419, train_acc = 0.9905, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0335, train_acc = 0.9925, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0270, train_acc = 0.9944, val_acc = 0.6000\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0523, train_acc = 0.9893, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0395, train_acc = 0.9916, val_acc = 0.6000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0335, train_acc = 0.9928, val_acc = 0.6000\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0440, train_acc = 0.9904, val_acc = 0.6000\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0336, train_acc = 0.9929, val_acc = 0.6150\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0286, train_acc = 0.9942, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0428, train_acc = 0.9902, val_acc = 0.5950\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0327, train_acc = 0.9927, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0262, train_acc = 0.9940, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0476, train_acc = 0.9893, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0362, train_acc = 0.9917, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0290, train_acc = 0.9935, val_acc = 0.6000\n",
      "\n",
      "--------\n",
      "EPOCH 18\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2928\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0453, train_acc = 0.9899, val_acc = 0.5450\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0325, train_acc = 0.9927, val_acc = 0.5500\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0282, train_acc = 0.9940, val_acc = 0.5700\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0488, train_acc = 0.9899, val_acc = 0.5650\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0390, train_acc = 0.9923, val_acc = 0.5550\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0324, train_acc = 0.9929, val_acc = 0.5650\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0423, train_acc = 0.9906, val_acc = 0.5550\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0323, train_acc = 0.9929, val_acc = 0.5550\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0264, train_acc = 0.9941, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0396, train_acc = 0.9910, val_acc = 0.5600\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0305, train_acc = 0.9930, val_acc = 0.5350\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0260, train_acc = 0.9940, val_acc = 0.5500\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0466, train_acc = 0.9895, val_acc = 0.5500\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0363, train_acc = 0.9920, val_acc = 0.5500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0294, train_acc = 0.9933, val_acc = 0.5500\n",
      "\n",
      "--------\n",
      "EPOCH 19\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2953\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0476, train_acc = 0.9904, val_acc = 0.5800\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0382, train_acc = 0.9918, val_acc = 0.5800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0296, train_acc = 0.9936, val_acc = 0.5850\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0442, train_acc = 0.9905, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0337, train_acc = 0.9923, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0278, train_acc = 0.9936, val_acc = 0.5800\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0434, train_acc = 0.9898, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0348, train_acc = 0.9922, val_acc = 0.5650\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0276, train_acc = 0.9934, val_acc = 0.5800\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0402, train_acc = 0.9919, val_acc = 0.5700\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0310, train_acc = 0.9930, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0244, train_acc = 0.9947, val_acc = 0.5750\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0427, train_acc = 0.9909, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0318, train_acc = 0.9927, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0249, train_acc = 0.9941, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 20\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2779\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0398, train_acc = 0.9920, val_acc = 0.5950\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0296, train_acc = 0.9929, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0246, train_acc = 0.9940, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0485, train_acc = 0.9900, val_acc = 0.5950\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0362, train_acc = 0.9921, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0295, train_acc = 0.9936, val_acc = 0.6000\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0405, train_acc = 0.9909, val_acc = 0.5900\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0299, train_acc = 0.9929, val_acc = 0.6000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0239, train_acc = 0.9949, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0451, train_acc = 0.9908, val_acc = 0.5900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0381, train_acc = 0.9922, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0286, train_acc = 0.9938, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0394, train_acc = 0.9918, val_acc = 0.5750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0317, train_acc = 0.9935, val_acc = 0.6050\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0255, train_acc = 0.9943, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 21\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2764\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0413, train_acc = 0.9913, val_acc = 0.5550\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0316, train_acc = 0.9925, val_acc = 0.5400\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0273, train_acc = 0.9935, val_acc = 0.5400\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0421, train_acc = 0.9911, val_acc = 0.5450\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0324, train_acc = 0.9932, val_acc = 0.5450\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0284, train_acc = 0.9930, val_acc = 0.5400\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0444, train_acc = 0.9909, val_acc = 0.5600\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0372, train_acc = 0.9925, val_acc = 0.5450\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0298, train_acc = 0.9935, val_acc = 0.5600\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0388, train_acc = 0.9916, val_acc = 0.5500\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0292, train_acc = 0.9938, val_acc = 0.5600\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0240, train_acc = 0.9946, val_acc = 0.5500\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0340, train_acc = 0.9929, val_acc = 0.5450\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0262, train_acc = 0.9946, val_acc = 0.5450\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0214, train_acc = 0.9954, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 22\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2913\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0387, train_acc = 0.9917, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0304, train_acc = 0.9930, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0237, train_acc = 0.9946, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0452, train_acc = 0.9913, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0352, train_acc = 0.9928, val_acc = 0.5600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0292, train_acc = 0.9939, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0398, train_acc = 0.9916, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0317, train_acc = 0.9925, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0256, train_acc = 0.9936, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0405, train_acc = 0.9915, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0301, train_acc = 0.9940, val_acc = 0.5750\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0262, train_acc = 0.9943, val_acc = 0.5850\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0394, train_acc = 0.9922, val_acc = 0.6000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0292, train_acc = 0.9939, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0241, train_acc = 0.9948, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 23\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2509\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0400, train_acc = 0.9911, val_acc = 0.6000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0315, train_acc = 0.9932, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0259, train_acc = 0.9939, val_acc = 0.6050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0413, train_acc = 0.9910, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0311, train_acc = 0.9928, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0248, train_acc = 0.9939, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0374, train_acc = 0.9919, val_acc = 0.6050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0292, train_acc = 0.9936, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0229, train_acc = 0.9946, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0353, train_acc = 0.9925, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0251, train_acc = 0.9945, val_acc = 0.6050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0206, train_acc = 0.9953, val_acc = 0.6000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0444, train_acc = 0.9919, val_acc = 0.6000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0347, train_acc = 0.9937, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0284, train_acc = 0.9946, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 24\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.3042\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0336, train_acc = 0.9923, val_acc = 0.5700\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0264, train_acc = 0.9939, val_acc = 0.5800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0204, train_acc = 0.9953, val_acc = 0.5700\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0430, train_acc = 0.9912, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0328, train_acc = 0.9935, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0282, train_acc = 0.9942, val_acc = 0.5700\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0388, train_acc = 0.9920, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0306, train_acc = 0.9930, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0243, train_acc = 0.9952, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0387, train_acc = 0.9917, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0289, train_acc = 0.9937, val_acc = 0.5900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0253, train_acc = 0.9943, val_acc = 0.5850\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0321, train_acc = 0.9931, val_acc = 0.5900\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0255, train_acc = 0.9946, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0194, train_acc = 0.9954, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 25\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2572\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0336, train_acc = 0.9922, val_acc = 0.6000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0271, train_acc = 0.9944, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0207, train_acc = 0.9952, val_acc = 0.6150\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0376, train_acc = 0.9931, val_acc = 0.6000\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0299, train_acc = 0.9941, val_acc = 0.6050\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0252, train_acc = 0.9951, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0321, train_acc = 0.9932, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0241, train_acc = 0.9948, val_acc = 0.6150\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0193, train_acc = 0.9957, val_acc = 0.6200\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0387, train_acc = 0.9922, val_acc = 0.6050\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0306, train_acc = 0.9935, val_acc = 0.6000\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0243, train_acc = 0.9951, val_acc = 0.6050\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0409, train_acc = 0.9913, val_acc = 0.5950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0309, train_acc = 0.9932, val_acc = 0.6100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0248, train_acc = 0.9947, val_acc = 0.6100\n",
      "\n",
      "--------\n",
      "EPOCH 26\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : "
     ]
    }
   ],
   "source": [
    "    print('\\nStarting Adversarial Training...')\n",
    "    oracle_loss = helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                                               start_letter=START_LETTER, gpu=CUDA)\n",
    "    print('\\nInitial Oracle Sample Loss : %.4f' % oracle_loss)\n",
    "\n",
    "    for epoch in range(ADV_TRAIN_EPOCHS):\n",
    "        print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
    "        # TRAIN GENERATOR\n",
    "        print('\\nAdversarial Training Generator : ', end='')\n",
    "        sys.stdout.flush()\n",
    "        train_generator_PG(gen, gen_optimizer, oracle, dis, 1)\n",
    "\n",
    "        # TRAIN DISCRIMINATOR\n",
    "        print('\\nAdversarial Training Discriminator : ')\n",
    "        train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
